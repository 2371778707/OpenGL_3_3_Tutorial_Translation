欢迎来到第十三课！今天讲法线贴图（normal mapping）。Welcome for our 13th tutorial ! Today we will talk about normal mapping.

从第八课：基本光照模型起，大家就知道了怎样利用三角形法线得到不错的光照效果。需要注意的一点是，截至目前，每个顶点仅有一个法线：在三角形三个顶点间，法线是平滑过渡的，而纹理颜色的采样方式恰与此相反。Since <a title="Tutorial 8 : Basic shading" href="http://www.opengl-tutorial.org/beginners-tutorials/tutorial-8-basic-shading/">Tutorial 8 : Basic shading</a> , you know how to get decent shading using triangle normals. One caveat is that until now, we only had one normal per vertex : inside each triangle, they vary smoothly, on the opposite to the colour, which samples a texture. The basic idea of normal mapping is to give normals similar variations.
<h1>法线纹理Normal textures</h1>
法线纹理看起来像这个样子：A "normal texture" looks like this :

<a href="http://www.opengl-tutorial.org/wp-content/uploads/2011/05/normal.jpg"><img class="alignnone size-full wp-image-307" title="normal" src="http://www.opengl-tutorial.org/wp-content/uploads/2011/05/normal.jpg" alt="" width="341" height="336" /></a>

每个纹素的RGB值实际上表示的是XYZ向量：颜色各分量的取值范围为0到1，而向量各分量的取值范围是-1到1，因此可以建立从纹素到法线的简单映射：In each RGB texel is encoded a XYZ vector : each colour component is between 0 and 1, and each vector component is between -1 and 1, so this simple mapping goes from the texel to the normal :
<pre class="brush:c">normal = (2*color)-1 // on each component</pre>
法线纹理大多呈现出蓝色，这是因为法线是朝上的（上方即Z轴所指方向，这和OpenGL中的Y轴朝上标准有所不同。这种差别显得很愚蠢，但既然无人愿意把那些个建模工具都重写一下，我们只好采取一些应对措施。后面还会再介绍。）The texture has a general blue tone because overall, the normal is up (so yeah, up is Z, which means that it's not our standard "Y=up" space. This is stupid but since nobody wants to recode all the tools, let's deal with it. More on this later.)

法线纹理和一般的颜色纹理映射方式类似。麻烦的是如何把法线从各三角形局部坐标系（切线坐标系tangent space，亦称图像坐标系image space）变换到模型坐标系（光照计算采用的坐标系）。This texture is mapped just like the diffuse one; The big problem is how to convert our normal, which is expressed in the space each individual triangle ( tangent space, also called image space), in model space (since this is what is used in our shading equation).
<h1>切线和双切线（Tangent and Bitangent）</h1>
想必大家对矩阵已经十分熟悉了。大家知道，要想定义一个坐标系（本例是切线坐标系）需要三个向量。现在朝上的向量已经有了，即法线，由Blender生成或做一个简单的叉乘积运算得到。还差三角形所在平面上的两个向量，即切线和双切线向量。“切线”一词系数学术语，即曲线的方向；而"双切线"则是因为这里我们面对的不是曲线，而是曲面，所以需要两个切线，故称“双切线”。You are now so familiar with matrices that you know that in order to define a space (in our case, the tangent space), we need 3 vectors. We already have our UP vector : it's the normal, given by Blender or computed from the triangle by a simple cross product. We need two more, in the plane of the triangle. They are called the Tangent and Bitangent vectors. "Tangent" because it is the standard mathematical term for the vector that is in the direction of a curve, and "Bitangent" because here we don't have a curve, we have a surface, so we need two tangents, hence "bitangent".

我们想把切线的方向转换到纹理坐标系中。We want to orient our tangents in the same direction than our texture coordinates.

若把三角形的两条边记为deltaPos1和deltaPos2，deltaUV1和deltaUV2是对应的UV坐标差值，那可以此问题可用如下式子表示：If we note deltaPos1 and deltaPos2 two edges of our triangle, and deltaUV1 and deltaUV2 the corresponding differences in UVs, we can express our problem with the following equation :
<pre class="brush:c">deltaPos1 = deltaUV1.x * T + deltaUV1.y * B
deltaPos2 = deltaUV2.x * T + deltaUV2.y * B</pre>
因此，已知T、B、N向量，可得下面这个漂亮的矩阵，完成模型坐标系到切线坐标系之间的变换：So given our T, B, N vectors, we've got this nice matrix which enables us to go from Model Space to Tangent Space :

<a href="http://www.opengl-tutorial.org/wp-content/uploads/2011/05/TBN.png"><img class="alignnone size-full wp-image-308 whiteborder" title="TBN" src="http://www.opengl-tutorial.org/wp-content/uploads/2011/05/TBN.png" alt="" width="107" height="66" /></a>

但我们需要的是却是从切线坐标系（纹理定义于其中）到模型坐标系（光照计算基于此）的变换。这只需对上述矩阵求逆即可，对于这个矩阵（正交阵，即各向量相互正交，请看后面“延伸阅读”小节）来说，其逆矩阵就是转置矩阵，计算十分简单：And since we wanted it exactly the other way around ( from Tangent Space, in which our texture is expressed, to Model Space, in which we can do lighting ), we simply have to take its inverse, which in this case (an orthogonal matrix, i.e each vector is perpendicular to the others. See "going further" below) is also its transpose, much cheaper to compute :
<pre class="brush:c">invTBN = transpose(TBN)</pre>
亦即：, i.e. :
<a href="http://www.opengl-tutorial.org/wp-content/uploads/2011/05/transposeTBN.png"><img class="alignnone size-full wp-image-309 whiteborder" title="transposeTBN" src="http://www.opengl-tutorial.org/wp-content/uploads/2011/05/transposeTBN.png" alt="" width="262" height="70" /></a>

小提示：顺序是T、B、N，而非T、N、B。前者更符合人们的预期。因为一般都把Z轴看作法线纹理的朝上向量（这也是法线纹理偏蓝色的原因，还记得前面的讲解么？）。Quick note : It's T,B,N instead of T,N,B as one would expect because normal textures assume that Z=up (hence the blue color, remember ?).
<h1>准备VBOPreparing our VBO</h1>
<h2>计算切线和双切线Computing the tangents and bitangents</h2>
我们得为整个模型计算好切线和双切线。用一个单独的函数完成这项工作：Since we need our tangents and bitangents on top of our normals, we have to compute them for the whole mesh. We'll do this in a separate function :
<pre class="brush: cpp">void computeTangentBasis(
    // inputs
    std::vector<glm::vec3> & vertices,
    std::vector<glm::vec2> & uvs,
    std::vector<glm::vec3> & normals,
    // outputs
    std::vector<glm::vec3> & tangents,
    std::vector<glm::vec3> & bitangents
){</pre>
为每个三角形计算边（deltaPos）和deltaUV For each triangle, we compute the edge (deltaPos) and the deltaUV
<pre class="brush: cpp">    for ( int i=0; i<vertices.size(); i+=3){

        // Shortcuts for vertices
        glm::vec3 & v0 = vertices[i+0];
        glm::vec3 & v1 = vertices[i+1];
        glm::vec3 & v2 = vertices[i+2];

        // Shortcuts for UVs
        glm::vec2 & uv0 = uvs[i+0];
        glm::vec2 & uv1 = uvs[i+1];
        glm::vec2 & uv2 = uvs[i+2];

        // Edges of the triangle : postion delta
        glm::vec3 deltaPos1 = v1-v0;
        glm::vec3 deltaPos2 = v2-v0;

        // UV delta
        glm::vec2 deltaUV1 = uv1-uv0;
        glm::vec2 deltaUV2 = uv2-uv0;</pre>
现在用公式来算切线和双切线：We can now use our formula to compute the tangent and the bitangent :
<pre class="brush: cpp">        float r = 1.0f / (deltaUV1.x * deltaUV2.y - deltaUV1.y * deltaUV2.x);
        glm::vec3 tangent = (deltaPos1 * deltaUV2.y   - deltaPos2 * deltaUV1.y)*r;
        glm::vec3 bitangent = (deltaPos2 * deltaUV1.x   - deltaPos1 * deltaUV2.x)*r;</pre>
最后，把这些切线和双切线缓存到数组。记住，还没为这些缓存的数据生成索引，因此每个顶点都有一份拷贝。Finally, we fill the <em>tangents </em>and <em>bitangents </em>buffers. Remember, these buffers are not indexed yet, so each vertex has its own copy.
<pre class="brush: cpp">        // Set the same tangent for all three vertices of the triangle.
        // They will be merged later, in vboindexer.cpp
        tangents.push_back(tangent);
        tangents.push_back(tangent);
        tangents.push_back(tangent);

        // Same thing for binormals
        bitangents.push_back(bitangent);
        bitangents.push_back(bitangent);
        bitangents.push_back(bitangent);

    }</pre>
<h2>生成索引Indexing</h2>
和往常一样为VBO生成索引，但有些许不同之处。Indexing our VBO is very similar to what we used to do, but there is a subtle difference.

若找到一个相同的顶点（相同的坐标、法线、纹理坐标），也就不需要再存一次切线和双切线；相反地，要求其平均值。把老代码改动一下吧：If we find a similar vertex (same position, same normal, same texture coordinates), we don't want to use its tangent and binormal too ; on the contrary, we want to average them. So let's modify our old code a bit :
<pre class="brush: cpp">        // Try to find a similar vertex in out_XXXX
        unsigned int index;
        bool found = getSimilarVertexIndex(in_vertices[i], in_uvs[i], in_normals[i],     out_vertices, out_uvs, out_normals, index);

        if ( found ){ // A similar vertex is already in the VBO, use it instead !
            out_indices.push_back( index );

            // Average the tangents and the bitangents
            out_tangents[index] += in_tangents[i];
            out_bitangents[index] += in_bitangents[i];
        }else{ // If not, it needs to be added in the output data.
            // Do as usual
            [...]
        }</pre>
注意，这里没做规范化操作。这样做很取巧，因为小三角形的切线和双切线向量也很小，相比于大三角形（对最终形状影响较大）来说，对最终得出的向量的影响也就小。Note that we don't normalize anything here. This is actually handy, because this way, small triangles, which have smaller tangent and bitangent vectors, will have a weaker effect on the final vectors than big triangles (which contribute more to the final shape).
<h1>着色器The shader</h1>
<h2>添加的缓冲区和uniform变量Additional buffers & uniforms</h2>
新加上两个缓冲区：分别存放切线和双切线：We need two new buffers : one for the tangents, and one for the bitangents :
<pre class="brush: cpp">    GLuint tangentbuffer;
    glGenBuffers(1, &tangentbuffer);
    glBindBuffer(GL_ARRAY_BUFFER, tangentbuffer);
    glBufferData(GL_ARRAY_BUFFER, indexed_tangents.size() * sizeof(glm::vec3), &indexed_tangents[0], GL_STATIC_DRAW);

    GLuint bitangentbuffer;
    glGenBuffers(1, &bitangentbuffer);
    glBindBuffer(GL_ARRAY_BUFFER, bitangentbuffer);
    glBufferData(GL_ARRAY_BUFFER, indexed_bitangents.size() * sizeof(glm::vec3), &indexed_bitangents[0], GL_STATIC_DRAW);</pre>
还需要一个uniform变量存储新的法线纹理：We also need a new uniform for our new normal texture :
<pre class="brush: cpp">    [...]
    GLuint NormalTexture = loadTGA_glfw("normal.tga");
    [...]
    GLuint NormalTextureID  = glGetUniformLocation(programID, "NormalTextureSampler");</pre>
另外一个uniform变量存储3x3的模型视图矩阵。严格地讲，这个矩阵不必要，但有它会更方便一点。稍后还会再讲这个。由于仅仅是计算方向，不需要位移部分，因此只需矩阵左上角的3x3子矩阵。And one for the 3x3 ModelView matrix. This is strictly speaking not necessary, but it's easier ; more about this later. We just need the 3x3 upper-left part because we will multiply directions, so we can drop the translation part.
<pre class="brush: cpp">    GLuint ModelView3x3MatrixID = glGetUniformLocation(programID, "MV3x3");</pre>
完整的绘制代码如下：So the full drawing code becomes :
<pre class="brush: cpp">        // Clear the screen
        glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);

        // Use our shader
        glUseProgram(programID);

        // Compute the MVP matrix from keyboard and mouse input
        computeMatricesFromInputs();
        glm::mat4 ProjectionMatrix = getProjectionMatrix();
        glm::mat4 ViewMatrix = getViewMatrix();
        glm::mat4 ModelMatrix = glm::mat4(1.0);
        glm::mat4 ModelViewMatrix = ViewMatrix * ModelMatrix;
        glm::mat3 ModelView3x3Matrix = glm::mat3(ModelViewMatrix); // Take the upper-left part of ModelViewMatrix
        glm::mat4 MVP = ProjectionMatrix * ViewMatrix * ModelMatrix;

        // Send our transformation to the currently bound shader,
        // in the "MVP" uniform
        glUniformMatrix4fv(MatrixID, 1, GL_FALSE, &MVP[0][0]);
        glUniformMatrix4fv(ModelMatrixID, 1, GL_FALSE, &ModelMatrix[0][0]);
        glUniformMatrix4fv(ViewMatrixID, 1, GL_FALSE, &ViewMatrix[0][0]);
        glUniformMatrix4fv(ViewMatrixID, 1, GL_FALSE, &ViewMatrix[0][0]);
        glUniformMatrix3fv(ModelView3x3MatrixID, 1, GL_FALSE, &ModelView3x3Matrix[0][0]);

        glm::vec3 lightPos = glm::vec3(0,0,4);
        glUniform3f(LightID, lightPos.x, lightPos.y, lightPos.z);

        // Bind our diffuse texture in Texture Unit 0
        glActiveTexture(GL_TEXTURE0);
        glBindTexture(GL_TEXTURE_2D, DiffuseTexture);
        // Set our "DiffuseTextureSampler" sampler to user Texture Unit 0
        glUniform1i(DiffuseTextureID, 0);

        // Bind our normal texture in Texture Unit 1
        glActiveTexture(GL_TEXTURE1);
        glBindTexture(GL_TEXTURE_2D, NormalTexture);
        // Set our "Normal    TextureSampler" sampler to user Texture Unit 0
        glUniform1i(NormalTextureID, 1);

        // 1rst attribute buffer : vertices
        glEnableVertexAttribArray(0);
        glBindBuffer(GL_ARRAY_BUFFER, vertexbuffer);
        glVertexAttribPointer(
            0,                  // attribute
            3,                  // size
            GL_FLOAT,           // type
            GL_FALSE,           // normalized?
            0,                  // stride
            (void*)0            // array buffer offset
        );

        // 2nd attribute buffer : UVs
        glEnableVertexAttribArray(1);
        glBindBuffer(GL_ARRAY_BUFFER, uvbuffer);
        glVertexAttribPointer(
            1,                                // attribute
            2,                                // size
            GL_FLOAT,                         // type
            GL_FALSE,                         // normalized?
            0,                                // stride
            (void*)0                          // array buffer offset
        );

        // 3rd attribute buffer : normals
        glEnableVertexAttribArray(2);
        glBindBuffer(GL_ARRAY_BUFFER, normalbuffer);
        glVertexAttribPointer(
            2,                                // attribute
            3,                                // size
            GL_FLOAT,                         // type
            GL_FALSE,                         // normalized?
            0,                                // stride
            (void*)0                          // array buffer offset
        );

        // 4th attribute buffer : tangents
        glEnableVertexAttribArray(3);
        glBindBuffer(GL_ARRAY_BUFFER, tangentbuffer);
        glVertexAttribPointer(
            3,                                // attribute
            3,                                // size
            GL_FLOAT,                         // type
            GL_FALSE,                         // normalized?
            0,                                // stride
            (void*)0                          // array buffer offset
        );

        // 5th attribute buffer : bitangents
        glEnableVertexAttribArray(4);
        glBindBuffer(GL_ARRAY_BUFFER, bitangentbuffer);
        glVertexAttribPointer(
            4,                                // attribute
            3,                                // size
            GL_FLOAT,                         // type
            GL_FALSE,                         // normalized?
            0,                                // stride
            (void*)0                          // array buffer offset
        );

        // Index buffer
        glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, elementbuffer);

        // Draw the triangles !
        glDrawElements(
            GL_TRIANGLES,      // mode
            indices.size(),    // count
            GL_UNSIGNED_INT,   // type
            (void*)0           // element array buffer offset
        );

        glDisableVertexAttribArray(0);
        glDisableVertexAttribArray(1);
        glDisableVertexAttribArray(2);
        glDisableVertexAttribArray(3);
        glDisableVertexAttribArray(4);

        // Swap buffers
        glfwSwapBuffers();</pre>
<h2>顶点着色器Vertex shader</h2>
和前面课程中讲的一样，所有计算都在观察坐标系里完成，这样的话获取片断的坐标会更容易一些。这就是为什么要用模型视图矩阵乘T、B、N向量。As said before, we'll do everything in camera space, because it's simpler to get the fragment's position in this space. This is why we multiply our T,B,N vectors with the ModelView matrix.
<pre class="brush:fs">    vertexNormal_cameraspace = MV3x3 * normalize(vertexNormal_modelspace);
    vertexTangent_cameraspace = MV3x3 * normalize(vertexTangent_modelspace);
    vertexBitangent_cameraspace = MV3x3 * normalize(vertexBitangent_modelspace);</pre>
这三个向量确定了TBN矩阵，其创建方式如下：These three vector define a the TBN matrix, which is constructed this way :
<pre>    mat3 TBN = transpose(mat3(
        vertexTangent_cameraspace,
        vertexBitangent_cameraspace,
        vertexNormal_cameraspace
    )); // You can use dot products instead of building this matrix and transposing it. See References for details.</pre>
此矩阵是从观察坐标系到切线坐标系的变换（若某矩阵名为XXX，则矩阵XXX_modelspace执行的是从模型坐标系到切线坐标系的变换）。可以利用它计算切线坐标系中的光线方向和视线方向。This matrix goes from camera space to tangent space (The same matrix, but with XXX_modelspace instead, would go from model space to tangent space). We can use it to compute the light direction and the eye direction, in tangent space :
<pre>    LightDirection_tangentspace = TBN * LightDirection_cameraspace;
    EyeDirection_tangentspace =  TBN * EyeDirection_cameraspace;</pre>
<h2>片断着色器Fragment shader</h2>
切线坐标系中的法线很容易获取：其实就是纹理：Our normal, in tangent space, is really straightforward to get : it's our texture :
<pre class="brush:fs">    // Local normal, in tangent space
    vec3 TextureNormal_tangentspace = normalize(texture2D( NormalTextureSampler, UV ).rgb*2.0 - 1.0);</pre>
?

一切准备就绪。So we've got everything we need now. Diffuse lighting uses <em>clamp( dot( n,l ), 0,1 )</em>, with n and l expressed in tangent space (it doesn't matter in which space you make your dot and cross products; the important thing is that n and l are both expressed in the same space). Specular lighting uses <em>clamp( dot( E,R ), 0,1 )</em>, again with E and R expressed in tangent space. Yay !
<h1>结果Results</h1>
这是目前得到的结果，可以看到：Here is our result so far. You can notice that :
<ul>
	<li>砖块看上去凹凸不平，这是因为法线变化丰富The bricks look bumpy because we have lots of variations in the normals</li>
	<li>水泥部分看上去很平整，这是因为这部分的法线纹理都是整齐划一的蓝色Cement looks flat because the? normal texture is uniformly blue</li>
</ul>
<a href="http://www.opengl-tutorial.org/wp-content/uploads/2011/05/normalmapping.png"><img class="alignnone size-large wp-image-315" title="normalmapping" src="http://www.opengl-tutorial.org/wp-content/uploads/2011/05/normalmapping-1024x793.png" alt="" width="640" height="495" /></a>
<h1>延伸阅读Going further</h1>
<h2>正交化Orthogonalization</h2>
In our vertex shader we took the transpose instead of the inverse because it's faster. But it only works if the space that the matrix represents is orthogonal, which is not yet the case. Luckily, this is very easy to fix : we just have to make the tangent perpendicular to the normal at he end of computeTangentBasis() :
<pre class="brush:vs">t = glm::normalize(t - n * glm::dot(n, t));</pre>
This formula may be hard to grasp, so a little schema might help :

<a href="http://www.opengl-tutorial.org/wp-content/uploads/2011/05/gramshmidt.png"><img class="alignnone size-full wp-image-319 whiteborder" title="gramshmidt" src="http://www.opengl-tutorial.org/wp-content/uploads/2011/05/gramshmidt.png" alt="" width="300" height="157" /></a>

n and t are almost perpendicular, so we "push" t in the direction of -n by a factor of dot(n,t)

<a href="http://www.cse.illinois.edu/iem/least_squares/gram_schmidt/">Here</a>'s a little applet that explains it too (Use only 2 vectors).
<h2>Handedness</h2>
You usually don't have to worry about that, but in some cases, when you use symmetric models, UVs are oriented in the wrong way, and your T has the wrong orientation.

To check whether it must be inverted or not, the check is simple : TBN must form a right-handed coordinate system, i.e. cross(n,t) must have the same orientation than b.

In mathematics, "Vector A has the same orientation as Vector B" translates as dot(A,B)>0, so we need to check if dot( cross(n,t) , b ) > 0.

If it's false, just invert t :
<pre class="brush: c">if (glm::dot(glm::cross(n, t), b) < 0.0f){
???? t = t * -1.0f;
 }</pre>
This is also done for each vertex at the end of computeTangentBasis().
<h2>镜面高光纹理Specular texture</h2>
Just for fun, I added a specular texture to the code. It looks like this :

<a href="http://www.opengl-tutorial.org/wp-content/uploads/2011/05/specular.jpg"><img class="alignnone size-full wp-image-317" title="specular" src="http://www.opengl-tutorial.org/wp-content/uploads/2011/05/specular.jpg" alt="" width="351" height="335" /></a>

and is used instead of the simple "vec3(0.3,0.3,0.3)" grey that we used as specular color.

<a href="http://www.opengl-tutorial.org/wp-content/uploads/2011/05/normalmappingwithspeculartexture.png"><img class="alignnone size-large wp-image-316" title="normalmappingwithspeculartexture" src="http://www.opengl-tutorial.org/wp-content/uploads/2011/05/normalmappingwithspeculartexture-1024x793.png" alt="" width="640" height="495" /></a>

Notice that now, cement is always black : the texture says that it has no specular component.
<h2>用立即模式进行调试Debugging with the immediate mode</h2>
The real aim of this website is that you DON'T use immediate mode, which is deprecated, slow, and problematic in many aspects.

However, it also happens to be really handy for debugging :

<a href="http://www.opengl-tutorial.org/wp-content/uploads/2011/05/immediatemodedebugging.png"><img class="alignnone size-large wp-image-314" title="immediatemodedebugging" src="http://www.opengl-tutorial.org/wp-content/uploads/2011/05/immediatemodedebugging-1024x793.png" alt="" width="640" height="495" /></a>

Here we visualize our tangent space with lines drawn in immediate mode.

For this, you need to abandon the 3.3 core profile :
<pre class="brush: cpp">glfwOpenWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_COMPAT_PROFILE);</pre>
then give our matrices to OpenGL's old-school pipeline (you can write another shader too, but it's simpler this way, and you're hacking anyway) :
<pre class="brush: cpp">glMatrixMode(GL_PROJECTION);
glLoadMatrixf((const GLfloat*)&ProjectionMatrix[0]);
glMatrixMode(GL_MODELVIEW);
glm::mat4 MV = ViewMatrix * ModelMatrix;
glLoadMatrixf((const GLfloat*)&MV[0]);</pre>
Disable shaders :
<pre class="brush: cpp">glUseProgram(0);</pre>
And draw your lines (in this case, normals, normalized and multiplied by 0.1, and applied at the correct vertex) :
<pre class="brush: cpp">glColor3f(0,0,1);
glBegin(GL_LINES);
for (int i=0; i<indices.size(); i++){
??? glm::vec3 p = indexed_vertices[indices[i]];
??? glVertex3fv(&p.x);
??? glm::vec3 o = glm::normalize(indexed_normals[indices[i]]);
??? p+=o*0.1f;
??? glVertex3fv(&p.x);
}
glEnd();</pre>
Remember : don't use immediate mode in real world ! Only for debugging ! And don't forget to re-enable the core profile afterwards, it will make sure that you don't do such things.
<h2>调试颜色Debugging with colors</h2>
When debugging, it can be useful to visualize the value of a vector. The easiest way to do this is to write it on the framebuffer instead of the actual colour. For instance, let's visualize LightDirection_tangentspace :
<pre class="brush:fs">color.xyz = LightDirection_tangentspace;</pre>
<a href="http://www.opengl-tutorial.org/wp-content/uploads/2011/05/colordebugging.png"><img class="alignnone size-large wp-image-313" title="colordebugging" src="http://www.opengl-tutorial.org/wp-content/uploads/2011/05/colordebugging-1024x793.png" alt="" width="640" height="495" /></a>

This means :
<ul>
	<li>On the right part of the cylinder, the light (represented by the small white line) is UP (in tangent space). In other words, the light is in the direction of the normal of the triangles.</li>
	<li>On the middle part of the cylinder, the light is in the direction of the tangent (towards +X)</li>
</ul>
友情提示：A few tips :
<ul>
	<li>Depending on what you're trying to visualize, you may want to normalize it.</li>
	<li>If you can't make sense of what you're seeing, visualize all components separately by forcing for instance green and blue to 0.</li>
	<li>Avoid messing with alpha, it's too complicated :)</li>
	<li>If you want to visualize negative value, you can use the same trick that our normal textures use : visualize (v+1.0)/2.0 instead, so that black means -1 and full color means +1. It's hard to understand what you see, though.</li>
</ul>
?
<h2>调试变量名Debugging with variable names</h2>
As already stated before, it's crucial to exactly know in which space your vectors are. Don't take the dot product of a vector in camera space and a vector in model space.

Appending the space of each vector in their names ("..._modelspace") helps fixing math bugs tremendously.
<h1>练习Exercises</h1>
<ul>
	<li>Normalize the vectors in indexVBO_TBN before the addition and see what it does.</li>
	<li>Visualize other vectors (for instance, EyeDirection_tangentspace) in color mode, and try to make sense of what you see</li>
</ul>
<h1>工具和链接Tools & Links</h1>
<ul>
	<li><a href="http://www.crazybump.com/">Crazybump</a> , a great tool to make normal maps. Not free.</li>
	<li><a href="http://developer.nvidia.com/nvidia-texture-tools-adobe-photoshop">Nvidia's photoshop plugin</a>. Free, but photoshop isn't...</li>
	<li><a href="http://www.zarria.net/nrmphoto/nrmphoto.html">Make your own normal maps out of several photos</a></li>
	<li><a href="http://www.katsbits.com/tutorials/textures/making-normal-maps-from-photographs.php">Make your own normal maps out of one photo</a></li>
	<li>Some more info on <a href="http://www.katjaas.nl/transpose/transpose.html">matrix transpose</a></li>
</ul>
<h1>参考文献References</h1>
<ul>
	<li><a href="http://www.terathon.com/code/tangent.html">Lengyel, Eric. “Computing Tangent Space Basis Vectors for an Arbitrary Mesh”. Terathon Software 3D Graphics Library, 2001.</a></li>
	<li><a href="http://www.amazon.com/dp/1568814240">Real Time Rendering, third edition</a></li>
	<li><a href="http://www.amazon.com/dp/1584504250">ShaderX4</a></li>
</ul>
?